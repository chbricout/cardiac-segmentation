{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_one_hot_encode(batch_segmentation_maps, num_classes):\n",
    "    \"\"\"\n",
    "    Perform one-hot encoding on a batch of segmentation maps.\n",
    "\n",
    "    Args:\n",
    "    - batch_segmentation_maps (torch.Tensor): Batch of segmentation map tensors with class indices.\n",
    "      Shape: (batch_size, H, W)\n",
    "    - num_classes (int): Number of classes in the segmentation task.\n",
    "\n",
    "    Returns:\n",
    "    - torch.Tensor: Batch of one-hot encoded tensors.\n",
    "      Shape: (batch_size, num_classes, H, W)\n",
    "    \"\"\"\n",
    "    # Ensure the batch_segmentation_maps is a PyTorch tensor\n",
    "    batch_segmentation_maps = torch.tensor(batch_segmentation_maps)\n",
    "\n",
    "    # Ensure the batch_segmentation_maps has the correct shape (batch_size, H, W)\n",
    "    if len(batch_segmentation_maps.shape) != 3:\n",
    "        raise ValueError(\"Batch segmentation maps should be a 3D tensor (batch_size, H, W).\")\n",
    "\n",
    "    # Create a zero-filled tensor with dimensions (batch_size, num_classes, H, W)\n",
    "    batch_one_hot = torch.zeros((batch_segmentation_maps.shape[0], num_classes, \n",
    "                                 batch_segmentation_maps.shape[1], batch_segmentation_maps.shape[2]))\n",
    "\n",
    "    # Fill in the one-hot tensor based on class indices for each batch\n",
    "    for batch_idx in range(batch_segmentation_maps.shape[0]):\n",
    "        for class_idx in range(num_classes):\n",
    "            batch_one_hot[batch_idx, class_idx, :, :] = (\n",
    "                batch_segmentation_maps[batch_idx, :, :] == class_idx\n",
    "            ).float()\n",
    "\n",
    "    return to_var(batch_one_hot)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming batch_segmentation_maps is your batch of segmentation map tensors with class indices\n",
    "# and num_classes is the number of classes in your segmentation task.\n",
    "batch_segmentation_maps = torch.tensor([[[0, 1, 0], [2, 1, 2], [0, 1, 2]],\n",
    "                                        [[2, 0, 1], [1, 2, 0], [0, 2, 1]]])\n",
    "num_classes = 3\n",
    "\n",
    "batch_one_hot_encoded = batch_one_hot_encode(batch_segmentation_maps, num_classes)\n",
    "print(batch_one_hot_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_to_seg(img, num_classes):\n",
    "    out = torch.zeros((1,*img.shape[1:])).to(img.device)\n",
    "    for i,layer in enumerate(img) :\n",
    "        out += layer*(i*255/(num_classes-1))\n",
    "    return out\n",
    "out_to_seg(batch_one_hot_encoded[0],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220c7dcc-8438-454d-97b1-8e989a7b8f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import isnan\n",
    "\n",
    "\n",
    "def runTraining():\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    ## DEFINE HYPERPARAMETERS (batch_size > 1)\n",
    "    batch_size = 3\n",
    "    batch_size_val = 3\n",
    "    lr = 0.0001  # Learning Rate\n",
    "    epoch = 21  # Number of epochs\n",
    "\n",
    "    root_dir = \"./Data/\"\n",
    "\n",
    "    print(\" Dataset: {} \".format(root_dir))\n",
    "\n",
    "    ## DEFINE THE TRANSFORMATIONS TO DO AND THE VARIABLES FOR TRAINING AND VALIDATION\n",
    "\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    mask_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    train_set_full = medicalDataLoader.MedicalImageDataset(\n",
    "        \"train\",\n",
    "        root_dir,\n",
    "        transform=transform,\n",
    "        mask_transform=mask_transform,\n",
    "        augment=True,\n",
    "        equalize=True,\n",
    "    )\n",
    "\n",
    "    train_loader_full = DataLoader(\n",
    "        train_set_full,\n",
    "        batch_size=batch_size,\n",
    "        worker_init_fn=np.random.seed(0),\n",
    "        num_workers=0,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    val_set = medicalDataLoader.MedicalImageDataset(\n",
    "        \"val\",\n",
    "        root_dir,\n",
    "        transform=transform,\n",
    "        mask_transform=mask_transform,\n",
    "        equalize=False,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size_val,\n",
    "        worker_init_fn=np.random.seed(0),\n",
    "        num_workers=0,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    ## INITIALIZE YOUR MODEL\n",
    "    num_classes = 4  # NUMBER OF CLASSES\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = \"Test_Model\"\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    net = UNet(num_classes)\n",
    "\n",
    "    print(\n",
    "        \"Total params: {0:,}\".format(\n",
    "            sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax()\n",
    "    CE_loss = torch.nn.CrossEntropyLoss(\n",
    "        weight=torch.Tensor([0.025, 0.05, 0.125, 0.8]), reduction=\"sum\"\n",
    "    )\n",
    "\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "        softMax.cuda()\n",
    "        CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    lossTotalTraining = []\n",
    "    Best_loss_val = 1000\n",
    "    BestEpoch = 0\n",
    "\n",
    "    directory = \"Results/Statistics/\" + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "    \n",
    "    ## FOR EACH EPOCH\n",
    "    for i in range(epoch):\n",
    "        net.train()\n",
    "        lossEpoch = []\n",
    "        DSCEpoch = []\n",
    "        DSCEpoch_w = []\n",
    "        num_batches = len(train_loader_full)\n",
    "        avg_per_layer = torch.Tensor([0, 0, 0, 0])\n",
    "        \n",
    "        \n",
    "        ## FOR EACH BATCH\n",
    "        for j, data in enumerate(train_loader_full):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data\n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = to_var(labels)\n",
    "            images = to_var(images)\n",
    "\n",
    "            ################### Train ###################\n",
    "            # -- The CNN makes its predictions (forward pass)\n",
    "            net_predictions = softMax(net(images))\n",
    "            # -- Compute the losses --#\n",
    "            # THIS FUNCTION IS TO CONVERT LABELS TO A FORMAT TO BE USED IN THIS CODE\n",
    "            segmentation_classes = getTargetSegmentation(labels)\n",
    "            encoded_classes = batch_one_hot_encode(segmentation_classes, num_classes)\n",
    "            # COMPUTE THE LOSS\n",
    "            CE_loss_value = CE_loss(\n",
    "                net_predictions, encoded_classes\n",
    "            )  # XXXXXX and YYYYYYY are your inputs for the CE\n",
    "            \n",
    "            # element_by_layers = predToSegmentation(net_predictions).sum(dim=(2, 3))\n",
    "            # prob_by_layer = element_by_layers / (element_by_layers.sum())\n",
    "            # if j == 0:\n",
    "            #     avg_per_layer = prob_by_layer\n",
    "            # else:\n",
    "            #     avg_per_layer = torch.mean(torch.stack([avg_per_layer, prob_by_layer]), dim=0)\n",
    "            # piecewise_diff = prob_by_layer - prob_by_layer_Cont_Average.to(\n",
    "            #     prob_by_layer.device\n",
    "            # )\n",
    "            # shannon = torch.pow(piecewise_diff, 2)\n",
    "            \n",
    "            lossTotal = CE_loss_value\n",
    "            # DO THE STEPS FOR BACKPROP (two things to be done in pytorch)\n",
    "            CE_loss_value.backward()\n",
    "            optimizer.step()\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "            lossEpoch.append(lossTotal.cpu().data.numpy())\n",
    "            printProgressBar(\n",
    "                j + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Training] Epoch: {} \".format(i),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(lossTotal),\n",
    "            )\n",
    "\n",
    "        lossEpoch = np.asarray(lossEpoch)\n",
    "        lossEpoch = lossEpoch.mean()\n",
    "\n",
    "        lossTotalTraining.append(lossEpoch)\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Training] Epoch: {}, LossG: {:.4f}\".format(i, lossEpoch),\n",
    "        )\n",
    "\n",
    "        ## THIS IS HOW YOU WILL SAVE THE TRAINED MODELS AFTER EACH EPOCH.\n",
    "        ## WARNING!!!!! YOU DON'T WANT TO SAVE IT AT EACH EPOCH, BUT ONLY WHEN THE MODEL WORKS BEST ON THE VALIDATION SET!!\n",
    "        if not os.path.exists(\"./models/\" + modelName):\n",
    "            os.makedirs(\"./models/\" + modelName)\n",
    "        if i == epoch - 1:\n",
    "            torch.save(\n",
    "                net.state_dict(), \"./models/\" + modelName + \"/\" + str(i) + \"_Epoch\"\n",
    "            )\n",
    "\n",
    "        np.save(os.path.join(directory, \"Losses.npy\"), lossTotalTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runTraining()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae10184-bacf-4c4d-9767-3272a76a0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = UNet(num_classes=4).cuda()\n",
    "mod.load_state_dict(torch.load(\"models/Test_Model/49_Epoch\"))\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                    \"./Data/\",\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=transform,\n",
    "                                                    equalize=False)\n",
    "\n",
    "val_loader = DataLoader(val_set,\n",
    "                            batch_size=2,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=False)\n",
    "inference(mod, val_loader, \"Test_Model\", 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask, path = val_set[4]\n",
    "out = mod(to_var(img)[None,:])\n",
    "out_cpu =out.detach().cpu()[0]\n",
    "out_cpu = torch.nn.functional.softmax(out_cpu, dim=0)\n",
    "segmentation_image = out_to_seg(predToSegmentation(out_cpu),3)\n",
    "\n",
    "# Now, concatenated_output has shape (batch_size, 1, num_classes, height, width)\n",
    "# If you want to remove the singleton dimension, you can use squeeze\n",
    "print(out_cpu.max(dim=0))\n",
    "fig, plots = plt.subplots(1,2, figsize=(20,20))\n",
    "plots[0].imshow(segmentation_image.permute(1,2,0), cmap=\"gray\")\n",
    "plots[1].imshow(mask.permute(1,2,0), cmap=\"gray\")\n",
    "mask.unique(), path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('Results/Statistics/Test_Model/Losses.npy')\n",
    "\n",
    "print(data)\n",
    "print(sum(data)/len(data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
